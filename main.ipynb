{
 "cells": [
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "** 0.0 / IMPORTS & INIT**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "0"
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import time\n",
    "import os\n",
    "\n",
    "import dash\n",
    "import dash_core_components as dcc\n",
    "import dash_html_components as html\n",
    "import plotly.express as px\n",
    "\n",
    "import pygal # Python SVG graph plotting library\n",
    "from pygal.style import NeonStyle # sexy af\n",
    "\n",
    "os.system('clear')"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "**1.1 / CSV IMPORTING**\n",
    "\n",
    "We import the 4 working databases from csv files in the subdirectory \"Base\" at the root of the current working directory through Pandas and assign them as Dataframes.                          \n",
    "We also display progress information, since the process can be quite lenghty.\n",
    "\n",
    "We declare constants to fetch only needed columns from each csv, reducing massively the computing power usage.\n",
    "\n",
    "~~Caution : When all bases are imported at once, they are all loaded into RAM and they can take up to 20G. If your machine can't handle it, you should comment out what you don't need and work sequentially.~~ \n",
    "Not necessary anymore now that we fetch only the columns we need. Base still takes about 10G."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants containing the columns we want to fetch from the csv's.\n",
    "COLS_AVANTAGE = ['ligne_identifiant', 'denomination_sociale', 'categorie', 'qualite', 'benef_codepostal', 'benef_ville', 'pays', 'benef_titre_libelle', 'benef_speicalite_libelle', 'benef_etablissement_codepostal', 'ligne_type', 'avant_date_signature', 'avant_montant_ttc']\n",
    "COLS_CONVENTION = ['ligne_identifiant', 'denomination_sociale', 'categorie', 'qualite', 'benef_codepostal', 'benef_ville', 'pays', 'benef_titre_libelle', 'benef_speicalite_libelle', 'benef_etablissement_codepostal', 'ligne_type', 'conv_date_signature', 'conv_objet', 'conv_montant_ttc']\n",
    "COLS_REMUNERATION = ['entreprise_identifiant', 'denomination_sociale', 'benef_categorie_code', 'qualite', 'benef_codepostal', 'pays', 'benef_titre_libelle', 'benef_speicalite_libelle', 'benef_etablissement_codepostal', 'remu_date', 'remu_montant_ttc']\n",
    "COLS_ENTREPRISE = ['pays','secteur','code_postal','ville']\n",
    "\n",
    "# # # # #  Commented for clarity, uncomment manually for linting # # # # # \n",
    "\n",
    "#    start = time.perf_counter() # starting time counter\n",
    "\n",
    "#    # Sequentially reads CSVs while displaying some basic progress info\n",
    "#    # Uses usecols= to only take columns defined in the constants above\n",
    "#    print('Started import.')\n",
    "#    print('-----------------------')\n",
    "\n",
    "#    print('Importing D_avantage...')\n",
    "#    D_avantage = pd.read_csv(\"Base/declaration_avantage_2020_02_19_04_00.csv\", sep = \";\", usecols = COLS_AVANTAGE)\n",
    "#    D_avantage.name = 'D_avantage'\n",
    "#    print('D_avantage successfully imported. 3 more to go.')\n",
    "\n",
    "#    print('Importing D_Convention...')\n",
    "#    D_Convention = pd.read_csv(\"Base/declaration_convention_2020_02_19_04_00.csv\", sep = \";\", usecols = COLS_CONVENTION)\n",
    "#    D_Convention.name = 'D_Convention'\n",
    "#    print('D_Convention successfully imported. 2 more to go.')\n",
    "\n",
    "#    print('Importing D_Remuneration...')\n",
    "#    D_Remuneration = pd.read_csv(\"Base/declaration_remuneration_2020_02_19_04_00.csv\", sep = \";\", usecols = COLS_REMUNERATION)\n",
    "#    D_Remuneration.name = 'D_Remuneration'\n",
    "#    print('D_Remuneration successfully imported. 1 more to go.')\n",
    "\n",
    "#    print('Importing Entreprise...')\n",
    "#    Entreprise = pd.read_csv(\"Base/entreprise_2020_02_19_04_00.csv\", sep = \",\", usecols = COLS_ENTREPRISE)\n",
    "#    Entreprise.name = 'Entreprise'\n",
    "#    print('Entreprise successfully imported.')\n",
    "\n",
    "    # Calculates and prints compute time\n",
    "#    success = time.perf_counter() \n",
    "#    import_time = int(success - start) \n",
    "#    print('-----------------------')\n",
    "#    print('All csv successfully imported in %s seconds.\\n\\n'%(import_time))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "**1.2 / DATAFRAMES CLEANING**\n",
    "\n",
    "We use a dictionary because we'll need it later.\n",
    "\n",
    "Order of operations :\n",
    "\n",
    "- Create the return dictionary\n",
    "- Get dataframe row indexes in a list\n",
    "- Iterate over that list and assign the values of the benef_codepostal column and the target indicator column\n",
    "- Format the values of benef_codepostal to keep only 2 digits, ignoring it if it is NaN, and turn it to a string\n",
    "- Cast the values of the target as an int, ignoring it if it's NaN\n",
    "- Iterate over the dictionary to check if the formatted value of benef_codepostal is already in there. If it's not, put it in along with its corresponding\n",
    "target column value. If it is, add the target column value to the existing dict value for that key.\n",
    "- Print various stats\n",
    "\n",
    "We return a dictionary with a 2-digit postal code as keys and an (most of the time) absurdly large number as values.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def comparator3000(df, fetch):\n",
    "    '''\n",
    "    Creates a dictionary {'Postal Code' : 'Total â‚¬ given'} with a \n",
    "    dataframe and a column of that dataframe.\n",
    "    '''\n",
    "\n",
    "    print('Started importing %s from %s.'%(fetch, df.name) )\n",
    "\n",
    "    # Init \n",
    "    dic = dict() \n",
    "    start = time.perf_counter()\n",
    "    q = list(df.index)\n",
    "    fc = 0\n",
    "    sc = 0\n",
    "\n",
    "    # Core\n",
    "    start = time.perf_counter() # starting time counter\n",
    "\n",
    "    for i in q:    \n",
    "        \n",
    "    # Progress bar\n",
    "        if i % int((len(q)/100)) == 0: \n",
    "            aa = int(i / len(q) * 100) \n",
    "            aa = str(aa)\n",
    "            print('%s %% processed.'%(aa))\n",
    "\n",
    "        # Dynamically assigning relevant column values from row i\n",
    "        cp = df['benef_codepostal'][i]\n",
    "        ttc = df[fetch][i]\n",
    "\n",
    "        # Type verification, splicing, and success/fail counts.\n",
    "        cp = str(cp)\n",
    "        cp = cp[:2]\n",
    "        try:\n",
    "            cp = int(cp)\n",
    "            cp = str(cp)\n",
    "            if len(cp) == 1:\n",
    "                cp = '0' + cp\n",
    "            else:\n",
    "                pass\n",
    "            ttc = int(ttc)\n",
    "            sc += 1\n",
    "        except ValueError:\n",
    "            fc += 1\n",
    "            continue\n",
    "\n",
    "\n",
    "\n",
    "        # Populating dictionary while correcting issues\n",
    "        if cp in dic:\n",
    "            dic[cp] += ttc\n",
    "        else:\n",
    "            dic[cp] = ttc\n",
    "\n",
    "    # Reporting compute time and successes/fails\n",
    "    success = time.perf_counter()\n",
    "    ns = int(success - start) \n",
    "    print('Succesfully imported %s from %s in %s seconds | %s rows had one or more missing values and were omitted | %s rows were usable\\n'%(fetch, df.name, ns, sc, fc))        \n",
    "\n",
    "    return dic\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** 2.1 / MAP VISUALIZATION WITH PYGAL (PYthon svg GrAph plotting Library) **\n",
    "\n",
    "Pygal allows to create dynamic maps as vectorial plots in xml optimized for HTML5 integration. It comes bundled with a detailled France map with regions and departments.\n",
    "\n",
    "We use it to import the France departments map, and pass it the values of our dictionary, along with a title for the top and a subtitle on each value.\n",
    "We then export it to a file that will be used by the HTML/CSS/JS renderer in an iframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_map(dic, title, subtitle):\n",
    "    '''\n",
    "    Creates a html file from a dictionary generated by comparator3000().\n",
    "    Asks for a Title (displayed at the top of the page) and a subtitle\n",
    "    (displayed over each department).\n",
    "    '''\n",
    "\n",
    "    # Core\n",
    "    fr_chart = pygal.maps.fr.Departments(human_readable=True, width=1080, height=1080, style=NeonStyle)\n",
    "    fr_chart.title = str(title)\n",
    "    fr_chart.add(str(subtitle), dic)\n",
    "\n",
    "    # Renders it and outputs to file in the current working directory\n",
    "    fr_chart.render_to_file('%s.html'%(title), 555)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** 2.2 / DASH **\n",
    "\n",
    "We create a dash server on localhost and fill it with simple data from the dataframes.\n",
    "The dash server will be called on localhost by the HTML/CSS/JS renderer in an iframe. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dash_runtime():\n",
    "\n",
    "    # Import feuille de style CSS\n",
    "    print('Styling...')\n",
    "    external_stylesheets = ['https://codepen.io/chriddyp/pen/bWLwgP.css']\n",
    "    app = dash.Dash(__name__, external_stylesheets=external_stylesheets)\n",
    "\n",
    "    # DÃ©finition des plots Ã  afficher\n",
    "    print('fig1 start')\n",
    "    fig1 = px.histogram(D_Remuneration, x=\"qualite\", y=\"remu_montant_ttc\", histfunc=\"avg\", title = 'Moyenne des rÃ©munÃ©rations par qualitÃ©', labels =                {'qualite':'QualitÃ©' , 'remu_montant_ttc':'Montant moyen TTC de la rÃ©munÃ©ration'}).update_xaxes(categoryorder=\"total descending\")\n",
    "    print('fig1 done')\n",
    "\n",
    "    print('fig2 start')\n",
    "    fig2 = px.histogram(D_avantage, x=\"qualite\", y=\"avant_montant_ttc\", histfunc=\"avg\", title = 'Moyenne des avantages accordÃ©s par qualitÃ©', labels =              {'qualite':'QualitÃ©' , 'avant_montant_ttc':'Montant moyen TTC des avantages accordÃ©s'}).update_xaxes(categoryorder=\"total descending\")\n",
    "    print('fig2 done')\n",
    "\n",
    "    print('fig3 start')\n",
    "    fig3 = px.histogram(D_Convention, x=\"conv_objet\", y=\"conv_montant_ttc\", histfunc=\"avg\", title = 'Moyenne des conventions signÃ©es par type', labels =            {'qualite':'Type de convention' , 'conv_montant_ttc':'Montant moyen TTC des conventions signÃ©es'}).update_xaxes(categoryorder=\"total descending\")\n",
    "    print('fig3 done')\n",
    "\n",
    "\n",
    "\n",
    "    # Layout Dash\n",
    "    app.layout = html.Div(children=[\n",
    "        html.H1(children='Transparence SantÃ©'),\n",
    "\n",
    "        html.Div(children='''\n",
    "            Visualisation de donnÃ©es Ã  partir de la base de donnÃ©es publique \"Transparence - SantÃ©\"\n",
    "        ''' ),\n",
    "        # Affichage des plots dÃ©finis plus haut \n",
    "        dcc.Graph(\n",
    "            id = 'Remun',\n",
    "            figure = fig1\n",
    "        ),\n",
    "\n",
    "        html.Div(children='''\n",
    "            Visualisation de donnÃ©es Ã  partir de la base de donnÃ©es publique \"Transparence - SantÃ©\"\n",
    "        ''' ),\n",
    "        # Affichage des plots dÃ©finis plus haut \n",
    "        dcc.Graph(\n",
    "            id = 'Avant',\n",
    "            figure = fig2\n",
    "        ),\n",
    "\n",
    "        html.Div(children='''\n",
    "            Visualisation de donnÃ©es Ã  partir de la base de donnÃ©es publique \"Transparence - SantÃ©\"\n",
    "        ''' ),\n",
    "        # Affichage des plots dÃ©finis plus haut \n",
    "        dcc.Graph(\n",
    "            id = 'Conv',\n",
    "            figure = fig3\n",
    "\n",
    "        )\n",
    "    ])\n",
    "\n",
    "\n",
    "    # Run Dash server\n",
    "    if __name__ == '__main__':\n",
    "        app.run_server(debug=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** 3.0 / RENDERER (WEBSITE) **\n",
    "\n",
    "We use a web page to display the whole project as one. \n",
    "\n",
    "HTML base, CSS styling, JavaScript for tabs and subtabs, iframes for embedding data\n",
    "\n",
    "See renderer.html"
   ]
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4-final"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
{
 "cells": [
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "** 0.0 / IMPORTS & INIT**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "import os\n",
    "import dash\n",
    "from jupyter_plotly_dash import JupyterDash\n",
    "import dash_core_components as dcc\n",
    "import dash_html_components as html\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import time\n",
    "import os\n",
    "import pygal # Python SVG graph plotting library\n",
    "from pygal.style import NeonStyle # sexy af"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "**1.1 / CSV IMPORTING**\n",
    "\n",
    "We import the 4 working databases from csv files in the subdirectory \"Base\" at the root of the current working directory through Pandas and assign them as Dataframes.                          \n",
    "We also display progress information, since the process can be quite lenghty.\n",
    "\n",
    "We declare constants to fetch only needed columns from each csv, reducing massively the computing power usage.\n",
    "\n",
    "~~Caution : When all bases are imported at once, they are all loaded into RAM and they can take up to 20G. If your machine can't handle it, you should comment out what you don't need and work sequentially.~~ \n",
    "Not necessary anymore now that we fetch only the columns we need. Base still takes about 10G."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Starting import...\n\n\nImporting D_avantage...\n"
    }
   ],
   "source": [
    "# Constants containing the columns we want to fetch from the csv's.\n",
    "COLS_AVANTAGE = ['ligne_identifiant', 'denomination_sociale', 'categorie', 'qualite', 'benef_codepostal', 'benef_ville', 'pays', 'benef_titre_libelle', 'benef_speicalite_libelle', 'benef_etablissement_codepostal', 'ligne_type', 'avant_date_signature', 'avant_montant_ttc']\n",
    "COLS_CONVENTION = ['ligne_identifiant', 'denomination_sociale', 'categorie', 'qualite', 'benef_codepostal', 'benef_ville', 'pays', 'benef_titre_libelle', 'benef_speicalite_libelle', 'benef_etablissement_codepostal', 'ligne_type', 'conv_date_signature', 'conv_montant_ttc']\n",
    "COLS_REMUNERATION = ['entreprise_identifiant', 'denomination_sociale', 'benef_categorie_code', 'qualite', 'benef_codepostal', 'pays', 'benef_titre_libelle', 'benef_speicalite_libelle', 'benef_etablissement_codepostal', 'remu_date', 'remu_montant_ttc']\n",
    "COLS_ENTREPRISE = ['pays','secteur','code_postal','ville']\n",
    "\n",
    "\n",
    "start = time.perf_counter() # starting time counter\n",
    "\n",
    "# Sequentially reads CSVs while displaying some basic progress info\n",
    "# Uses usecols= to only take columns defined in the constants above\n",
    "print('Started import.')\n",
    "print('-----------------------')\n",
    "\n",
    "print('Importing D_avantage...')\n",
    "D_avantage = pd.read_csv(\"Base/declaration_avantage_2020_02_19_04_00.csv\", sep = \";\", usecols = COLS_AVANTAGE)\n",
    "D_avantage.name = 'D_avantage'\n",
    "print('D_avantage successfully imported. 3 more to go.')\n",
    "\n",
    "print('Importing D_Convention...')\n",
    "D_Convention = pd.read_csv(\"Base/declaration_convention_2020_02_19_04_00.csv\", sep = \";\", usecols = COLS_CONVENTION)\n",
    "D_Convention.name = 'D_Convention'\n",
    "print('D_Convention successfully imported. 2 more to go.')\n",
    "\n",
    "print('Importing D_Remuneration...')\n",
    "D_Remuneration = pd.read_csv(\"Base/declaration_remuneration_2020_02_19_04_00.csv\", sep = \";\", usecols = COLS_REMUNERATION)\n",
    "D_Remuneration.name = 'D_Remuneration'\n",
    "print('D_Remuneration successfully imported. 1 more to go.')\n",
    "\n",
    "print('Importing Entreprise...')\n",
    "Entreprise = pd.read_csv(\"Base/entreprise_2020_02_19_04_00.csv\", sep = \",\", usecols = COLS_ENTREPRISE)\n",
    "Entreprise.name = 'Entreprise'\n",
    "print('Entreprise successfully imported.')\n",
    "\n",
    "# Calculates and prints compute time\n",
    "success = time.perf_counter() \n",
    "import_time = int(success - start) \n",
    "print('-----------------------')\n",
    "print('All csv successfully imported in %s seconds.\\n\\n'%(import_time))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "**1.2 / DATAFRAMES CLEANING**\n",
    "\n",
    "We use a dictionary because we'll need it later.\n",
    "\n",
    "Order of operations :\n",
    "\n",
    "- Create the return dictionary\n",
    "- Get dataframe row indexes in a list\n",
    "- Iterate over that list and assign the values of the benef_codepostal column and the target indicator column\n",
    "- Format the values of benef_codepostal to keep only 2 digits, ignoring it if it is NaN, and turn it to a string\n",
    "- Cast the values of the target as an int, ignoring it if it's NaN\n",
    "- Iterate over the dictionary to check if the formatted value of benef_codepostal is already in there. If it's not, put it in along with its corresponding\n",
    "target column value. If it is, add the target column value to the existing dict value for that key.\n",
    "- Print various stats\n",
    "\n",
    "We return a dictionary with a 2-digit postal code as keys and an (most of the time) absurdly large number as values.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def comparator3000(df, fetch):\n",
    "    '''\n",
    "    Creates a dictionary {'Postal Code' : 'Total € given'} with a \n",
    "    dataframe and a column of that dataframe.\n",
    "    '''\n",
    "\n",
    "    print('Started importing %s from %s.'%(fetch, df.name) )\n",
    "\n",
    "    # Init \n",
    "    dic = dict() \n",
    "    start = time.perf_counter()\n",
    "    q = list(df.index)\n",
    "    fc = 0\n",
    "    sc = 0\n",
    "\n",
    "    # Core\n",
    "    for i in q:\n",
    "\n",
    "        # Progress bar\n",
    "        if i % int((len(q)/100)) == 0: \n",
    "            aa = int(i / len(q) * 100) \n",
    "            aa = str(aa)\n",
    "            print('%s %% processed.'%(aa))\n",
    "\n",
    "        # Dynamically assigning relevant column values from row i\n",
    "        cp = df['benef_codepostal'][i]\n",
    "        ttc = df[fetch][i]\n",
    "\n",
    "        # Type verification, splicing, and success/fail counts.\n",
    "        cp = str(cp)\n",
    "        cp = cp[:2]\n",
    "        try:\n",
    "            cp = int(cp)\n",
    "            cp = str(cp)\n",
    "            if len(cp) == 1:\n",
    "                cp = '0' + cp\n",
    "            else:\n",
    "                pass\n",
    "            ttc = int(ttc)\n",
    "            sc += 1\n",
    "        except ValueError:\n",
    "            fc += 1\n",
    "            continue\n",
    "\n",
    "    \n",
    "\n",
    "        # Populating dictionary while correcting issues\n",
    "        if cp in dic:\n",
    "            dic[cp] += ttc\n",
    "        else:\n",
    "            dic[cp] = ttc\n",
    "\n",
    "    # Reporting compute time and successes/fails\n",
    "    success = time.perf_counter()\n",
    "    ns = int(success - start) \n",
    "    print('Succesfully imported %s from %s in %s seconds | %s rows had one or more missing values and were omitted | %s rows were usable\\n'%(fetch, df.name, ns, sc, fc))        \n",
    "\n",
    "    return dic\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** 2.1 / MAP VISUALIZATION WITH PYGAL (PYthon svg GrAph plotting Library) **\n",
    "\n",
    "Pygal allows to create dynamic maps as vectorial plots in xml optimized for HTML5 integration. It comes bundled with a detailled France map with regions and departments.\n",
    "\n",
    "We use it to import the France departments map, and pass it the values of our dictionary, along with a title for the top and a subtitle on each value.\n",
    "We then export it to a file that will be used by the HTML/CSS/JS renderer in an iframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_map(dic, title, subtitle):\n",
    "    '''\n",
    "    Creates a html file from a dictionary generated by comparator3000().\n",
    "    Asks for a Title (displayed at the top of the page) and a subtitle\n",
    "    (displayed over each department).\n",
    "    '''\n",
    "\n",
    "    # Core\n",
    "    fr_chart = pygal.maps.fr.Departments(human_readable=True, width=1080, height=1080, style=NeonStyle)\n",
    "    fr_chart.title = str(title)\n",
    "    fr_chart.add(str(subtitle), dic)\n",
    "\n",
    "    # Renders it and outputs to file in the current working directory\n",
    "    fr_chart.render_to_file('%s.html'%(title), 555)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** DASH **\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "external_stylesheets = ['https://codepen.io/chriddyp/pen/bWLwgP.css']\n",
    "\n",
    "app = dash.Dash(__name__, external_stylesheets=external_stylesheets)\n",
    "\n",
    "app.layout = html.Div(children=[\n",
    "    html.H1(children='Transparence Santé'),\n",
    "\n",
    "    html.Div(children='''\n",
    "        Visualisation de données à partir de la base de données publique Transparence - Santé\n",
    "    ''' ),\n",
    "\n",
    "    dcc.Graph(\n",
    "        id='example-graph',\n",
    "        figure={\n",
    "            'data': [\n",
    "                {'x': [1, 2, 3], 'y': [1, 1, 2], 'type': 'bar', 'name': ':hap:'},\n",
    "                {'x': [1, 2, 3], 'y': [2, 4, 5], 'type': 'bar', 'name': u':noel:'},\n",
    "            ],\n",
    "            'layout': {\n",
    "                'title': 'Dash Data Visualization'\n",
    "            }\n",
    "\n",
    "        }\n",
    "    )\n",
    "])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run_server(debug=True)"
   ]
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4-final"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 2
}